{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size = (1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis = 0)\n",
    "\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.9309887850104133e-18\n",
      "-1.727260490001239\n",
      "1.7317037546244094\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm.mean())\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.min(axis = 0).mean())\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.max(axis = 0).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[235 195 507  24 787  55 122 854 548 782 319 722  57 207 515  32 740 622\n",
      " 373 936  58 492 217 248 720 585 516 188 896  97 255 438 121 360 886 136\n",
      " 602 266 142 844 514 822 349 326 713 506 323 759 119 350 700 417   4 112\n",
      "  91 818 415 223 419 915 793 809 287 534 982 783 456 192 477 394 423 401\n",
      " 276 236 284 524 884 843 868 164 962 693  44 883 315 579 300 189 582 731\n",
      " 715 944 588 493 695 642 543  37 472 656 665 795 509 377 512 259 765 945\n",
      " 103 748 254 760 581 911 732 144 989  40 344 495 850 646 544 500 530 594\n",
      " 575 997 568  85 293 389 182 586 257 895 241 246 400 856 525 399 332 127\n",
      " 263 216 441 376  43 876 533 870 460 411 374 702 659 358 750 973 908 380\n",
      " 817 781 483 181 185 914 242 204 839 829   3 147 862 219 363 848 607 272\n",
      " 201 792 961 406  86 930 133 564 343 888 433 258 651 356 986 128 687 442\n",
      " 253 869 660  75 667 699 669 412 368 199 519 290 527 821  38 132 768  90\n",
      " 446 846  29 966 221  81 398 327 420 531 163 227 698 791 638 529 723 464\n",
      " 995  77 502 457 123 890 437 338 555 430  67 790 941 273 286  46 177 719\n",
      "  19 737 975 378 934 180 542 747 618  53 385 810   6 226 866  73 741 458\n",
      " 243 899 476 730 990 617  11 557  80 218 155 802 614 535 104 504 471  63\n",
      " 150 205 311 834  25 751  61 615 108 811 835 551 881 418 686 610 467 178\n",
      " 450 214  70 670 858 561 574 907 496 633  69  27 814 443 637 116 620 285\n",
      " 921  31 208 960 383 647 560  87 402 827 279 260 465  39 166 984 801 478\n",
      " 314  42 784 683  50 830 772 710 330 289 828 277 770 427 384 902 301 440\n",
      " 393  47 480 497 987 145 684 475 939 576 703 408 672  92 697 469 654 138\n",
      " 965 422 880 711 364 498 233 922 505 599 852 336 173 721   1 305 797 812\n",
      " 545 605 352 675 416 439 309 577   0 386 806 662  71 274 553 913 832 230\n",
      " 774 179 211 753 202 609 974 303 779 310  59 554 752 444 775 321 931 736\n",
      " 780 875 526 171 451 479 681 571 186 608 799 570 157 999 877 337 197  95\n",
      " 379 923 808 946 624 717 348 124 361 929 429 785 796  98 882 541 340 904\n",
      " 481 390 271 985 345 403 707 357 824 940 265 342 152 805 705 942 395 562\n",
      " 485 426 938 955 726 291 252 729 434 351 954 804 716 149 228 671 778 743\n",
      " 359 956  15 855 268 891 819 537 262 885 981 807 234 275 634 139 109  52\n",
      " 627 381 238 714 169 536 926 294 232 200 491 517 135   5  28 701 632 692\n",
      " 958 413 655 712  13 964 187 917 370  79 409 148 522  84 209 789 565 388\n",
      " 978 176 513  33 849 901  45 776 968 304 709 239 952  82 977 318  60 833\n",
      " 461 927 979 871 532 539 490 126 983 346 798 141 691 898 771 971 264 151\n",
      " 863  49  89 117 935 861  10 267 194 425 621 333 247 484 905 118 167 992\n",
      " 649 292 325 249 329 583 168 678 894 328 313 769 668 619 251 640 853 967\n",
      " 320 215   2 540 212 738 677 518 508 657 928 369 552 499 584 237 367 278\n",
      " 845 953 949 101 160 140 391 280 641 306 414 172 611 767 803 673 143  72\n",
      " 105  16  20 261 906 245 100 302 487 735  48 991 694   7 744 397 231 598\n",
      " 175 650 269 745 676 347 996 813 213 601 110 193 924  36 432 596 312 362\n",
      " 154 353 786 191 758 887 838 859  17 486 749 240 421 488 648 613 591  41\n",
      " 455 773 864  51 331  93 295 563 661 980 874 511 190 733 865  65 841  18\n",
      " 162 225 993 102 463 970 538 628 909 762 341  23 815  54 170 307 547 994\n",
      " 556 903 131 474 120 857 950 196 404 283 631 454 718 959 296 424 569 988\n",
      " 636 206 706 788 473 666 879 165 198 689 159 682 919 685 674 872 800 643\n",
      " 244 453 387 889 595  64 494 334  12 590  78 297 816 317  21 679 372 549\n",
      " 757 947 645 600 754 836 635 933 322  14 727 724 616 998 630 111 203 688\n",
      " 728 604 639 912 826 734 653 704 893 823 725 837 107 766 755 612 825 468\n",
      " 957 299 436 963 459 831 256 708   9   8 925  68 972 937 851 339 625 445\n",
      " 546 742 578 462 431 501  96 156  83 696 916 482 867 644 220 969 316 428\n",
      " 365 873 756 520 335 115 521 847  99  66 210 396 566 658 449  74 466  34\n",
      " 447 183 897 777 129 137 892 435 918 690 153 761 174  62 664 250 470 282\n",
      " 114 125 308 573 567  22 528 559 763 976 106 932 580 324 558 270 113  94\n",
      " 134 593 355 878 603 405 161  26 288 452 224 184 366 606 951 663 587 489\n",
      "  88 900 629 158 229 392 281 407 626 910 820  56 503 222  35 592 794 371\n",
      " 597 680 764 550 382 589 298 354 130 652 410 523 860 739 920 842 943 510\n",
      " 623 572 840 948 448 375 746  76 146  30]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "print(X_norm.shape[0])\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:600],:]\n",
    "print(X_train.shape)\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[600:800],:]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = row_indices[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.randint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of X_train\n",
    "\n",
    "\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "\n",
    "\n",
    "# Print the shape of X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
